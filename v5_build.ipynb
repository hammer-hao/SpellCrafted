{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model params\n",
    "torch.manual_seed(69)\n",
    "batch_size=16\n",
    "block_size=36\n",
    "sampling_size=24\n",
    "max_iters=1000\n",
    "eval_interval=300\n",
    "learning_rate=3e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 32\n",
    "n_heads = 4\n",
    "n_layers = 4\n",
    "dropout=0.3\n",
    "\n",
    "prompt_size = block_size # 30 maximum tokens allowed in the prompt\n",
    "encoder_num_heads=4\n",
    "encoder_n_embd=n_embd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tokenizer trainer\n",
    "from tokenizers import Tokenizer\n",
    "tokenizer = Tokenizer.from_file(\"mtggenerator.json\")\n",
    "vocab_size=tokenizer.get_vocab_size()\n",
    "\n",
    "#create the mapping from characters to integers\n",
    "encode = lambda text: tokenizer.encode(text).ids #encode: take a string, output a list of integers\n",
    "decode = lambda list: tokenizer.decode(list) #decode: take a list of integers, output a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mana_cost</th>\n",
       "      <th>cmc</th>\n",
       "      <th>type_line</th>\n",
       "      <th>oracle_text</th>\n",
       "      <th>power</th>\n",
       "      <th>toughness</th>\n",
       "      <th>colors</th>\n",
       "      <th>color_identity</th>\n",
       "      <th>keywords</th>\n",
       "      <th>rarity</th>\n",
       "      <th>flavor_text</th>\n",
       "      <th>text</th>\n",
       "      <th>text_prompt</th>\n",
       "      <th>card_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fury Sliver</td>\n",
       "      <td>{5}{R}</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Creature — Sliver</td>\n",
       "      <td>All Sliver creatures have double strike.</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>['R']</td>\n",
       "      <td>['R']</td>\n",
       "      <td>[]</td>\n",
       "      <td>uncommon</td>\n",
       "      <td>\"A rift opened, and our arrows were abruptly s...</td>\n",
       "      <td>Fury Sliver: [SEP] {5}{R} [SEP] Creature — Sli...</td>\n",
       "      <td>Fury Sliver: [SEP] {5}{R}</td>\n",
       "      <td>Creature — Sliver [SEP] All Sliver creatures h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kor Outfitter</td>\n",
       "      <td>{W}{W}</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Creature — Kor Soldier</td>\n",
       "      <td>When ~ enters the battlefield, you may attach ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>['W']</td>\n",
       "      <td>['W']</td>\n",
       "      <td>[]</td>\n",
       "      <td>common</td>\n",
       "      <td>\"We take only what we need to survive. Believe...</td>\n",
       "      <td>Kor Outfitter: [SEP] {W}{W} [SEP] Creature — K...</td>\n",
       "      <td>Kor Outfitter: [SEP] {W}{W}</td>\n",
       "      <td>Creature — Kor Soldier [SEP] When ~ enters the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spirit</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Token Creature — Spirit</td>\n",
       "      <td>Flying</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>['W']</td>\n",
       "      <td>['W']</td>\n",
       "      <td>[Flying]</td>\n",
       "      <td>common</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spirit: [SEP]  [SEP] Token Creature — Spirit [...</td>\n",
       "      <td>Spirit: [SEP]</td>\n",
       "      <td>Token Creature — Spirit [SEP] Flying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Siren Lookout</td>\n",
       "      <td>{2}{U}</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Creature — Siren Pirate</td>\n",
       "      <td>Flying\\nWhen ~ enters the battlefield, it expl...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>['U']</td>\n",
       "      <td>['U']</td>\n",
       "      <td>[Flying, Explore]</td>\n",
       "      <td>common</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Siren Lookout: [SEP] {2}{U} [SEP] Creature — S...</td>\n",
       "      <td>Siren Lookout: [SEP] {2}{U}</td>\n",
       "      <td>Creature — Siren Pirate [SEP] Flying\\nWhen ~ e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Web</td>\n",
       "      <td>{G}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Enchantment — Aura</td>\n",
       "      <td>Enchant creature (Target a creature as you cas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['G']</td>\n",
       "      <td>['G']</td>\n",
       "      <td>[Enchant]</td>\n",
       "      <td>rare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web: [SEP] {G} [SEP] Enchantment — Aura [SEP] ...</td>\n",
       "      <td>Web: [SEP] {G}</td>\n",
       "      <td>Enchantment — Aura [SEP] Enchant creature (Tar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85059</th>\n",
       "      <td>Celestine Reef</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Plane — Luvion</td>\n",
       "      <td>Creatures without flying or islandwalk can't a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>rare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Celestine Reef: [SEP]  [SEP] Plane — Luvion [S...</td>\n",
       "      <td>Celestine Reef: [SEP]</td>\n",
       "      <td>Plane — Luvion [SEP] Creatures without flying ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85060</th>\n",
       "      <td>Horned Troll</td>\n",
       "      <td>{2}{G}</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Creature — Troll</td>\n",
       "      <td>{G}: Regenerate ~.</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>['G']</td>\n",
       "      <td>['G']</td>\n",
       "      <td>[]</td>\n",
       "      <td>common</td>\n",
       "      <td>Sword hilts jut from some trolls' bodies where...</td>\n",
       "      <td>Horned Troll: [SEP] {2}{G} [SEP] Creature — Tr...</td>\n",
       "      <td>Horned Troll: [SEP] {2}{G}</td>\n",
       "      <td>Creature — Troll [SEP] {G}: Regenerate ~.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85061</th>\n",
       "      <td>Faerie Bladecrafter</td>\n",
       "      <td>{2}{B}</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Creature — Faerie Rogue</td>\n",
       "      <td>Flying\\nWhenever one or more Faeries you contr...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>['B']</td>\n",
       "      <td>['B']</td>\n",
       "      <td>[Flying]</td>\n",
       "      <td>rare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Faerie Bladecrafter: [SEP] {2}{B} [SEP] Creatu...</td>\n",
       "      <td>Faerie Bladecrafter: [SEP] {2}{B}</td>\n",
       "      <td>Creature — Faerie Rogue [SEP] Flying\\nWhenever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85062</th>\n",
       "      <td>Exultant Skymarcher</td>\n",
       "      <td>{1}{W}{W}</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Creature — Vampire Soldier</td>\n",
       "      <td>Flying</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>['W']</td>\n",
       "      <td>['W']</td>\n",
       "      <td>[Flying]</td>\n",
       "      <td>common</td>\n",
       "      <td>\"We have come at last to this holiest of holy ...</td>\n",
       "      <td>Exultant Skymarcher: [SEP] {1}{W}{W} [SEP] Cre...</td>\n",
       "      <td>Exultant Skymarcher: [SEP] {1}{W}{W}</td>\n",
       "      <td>Creature — Vampire Soldier [SEP] Flying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85063</th>\n",
       "      <td>Disintegrate</td>\n",
       "      <td>{X}{R}</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sorcery</td>\n",
       "      <td>~ deals X damage to any target. If it's a crea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['R']</td>\n",
       "      <td>['R']</td>\n",
       "      <td>[]</td>\n",
       "      <td>common</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Disintegrate: [SEP] {X}{R} [SEP] Sorcery [SEP]...</td>\n",
       "      <td>Disintegrate: [SEP] {X}{R}</td>\n",
       "      <td>Sorcery [SEP] ~ deals X damage to any target. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82351 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      name  mana_cost  cmc                   type_line  \\\n",
       "0              Fury Sliver     {5}{R}  6.0           Creature — Sliver   \n",
       "1            Kor Outfitter     {W}{W}  2.0      Creature — Kor Soldier   \n",
       "2                   Spirit        NaN  0.0     Token Creature — Spirit   \n",
       "3            Siren Lookout     {2}{U}  3.0     Creature — Siren Pirate   \n",
       "4                      Web        {G}  1.0          Enchantment — Aura   \n",
       "...                    ...        ...  ...                         ...   \n",
       "85059       Celestine Reef        NaN  0.0              Plane — Luvion   \n",
       "85060         Horned Troll     {2}{G}  3.0            Creature — Troll   \n",
       "85061  Faerie Bladecrafter     {2}{B}  3.0     Creature — Faerie Rogue   \n",
       "85062  Exultant Skymarcher  {1}{W}{W}  3.0  Creature — Vampire Soldier   \n",
       "85063         Disintegrate     {X}{R}  1.0                     Sorcery   \n",
       "\n",
       "                                             oracle_text power toughness  \\\n",
       "0               All Sliver creatures have double strike.     3         3   \n",
       "1      When ~ enters the battlefield, you may attach ...     2         2   \n",
       "2                                                 Flying     1         1   \n",
       "3      Flying\\nWhen ~ enters the battlefield, it expl...     1         2   \n",
       "4      Enchant creature (Target a creature as you cas...   NaN       NaN   \n",
       "...                                                  ...   ...       ...   \n",
       "85059  Creatures without flying or islandwalk can't a...   NaN       NaN   \n",
       "85060                                 {G}: Regenerate ~.     2         2   \n",
       "85061  Flying\\nWhenever one or more Faeries you contr...     2         2   \n",
       "85062                                             Flying     2         3   \n",
       "85063  ~ deals X damage to any target. If it's a crea...   NaN       NaN   \n",
       "\n",
       "      colors color_identity           keywords    rarity  \\\n",
       "0      ['R']          ['R']                 []  uncommon   \n",
       "1      ['W']          ['W']                 []    common   \n",
       "2      ['W']          ['W']           [Flying]    common   \n",
       "3      ['U']          ['U']  [Flying, Explore]    common   \n",
       "4      ['G']          ['G']          [Enchant]      rare   \n",
       "...      ...            ...                ...       ...   \n",
       "85059     []             []                 []      rare   \n",
       "85060  ['G']          ['G']                 []    common   \n",
       "85061  ['B']          ['B']           [Flying]      rare   \n",
       "85062  ['W']          ['W']           [Flying]    common   \n",
       "85063  ['R']          ['R']                 []    common   \n",
       "\n",
       "                                             flavor_text  \\\n",
       "0      \"A rift opened, and our arrows were abruptly s...   \n",
       "1      \"We take only what we need to survive. Believe...   \n",
       "2                                                    NaN   \n",
       "3                                                    NaN   \n",
       "4                                                    NaN   \n",
       "...                                                  ...   \n",
       "85059                                                NaN   \n",
       "85060  Sword hilts jut from some trolls' bodies where...   \n",
       "85061                                                NaN   \n",
       "85062  \"We have come at last to this holiest of holy ...   \n",
       "85063                                                NaN   \n",
       "\n",
       "                                                    text  \\\n",
       "0      Fury Sliver: [SEP] {5}{R} [SEP] Creature — Sli...   \n",
       "1      Kor Outfitter: [SEP] {W}{W} [SEP] Creature — K...   \n",
       "2      Spirit: [SEP]  [SEP] Token Creature — Spirit [...   \n",
       "3      Siren Lookout: [SEP] {2}{U} [SEP] Creature — S...   \n",
       "4      Web: [SEP] {G} [SEP] Enchantment — Aura [SEP] ...   \n",
       "...                                                  ...   \n",
       "85059  Celestine Reef: [SEP]  [SEP] Plane — Luvion [S...   \n",
       "85060  Horned Troll: [SEP] {2}{G} [SEP] Creature — Tr...   \n",
       "85061  Faerie Bladecrafter: [SEP] {2}{B} [SEP] Creatu...   \n",
       "85062  Exultant Skymarcher: [SEP] {1}{W}{W} [SEP] Cre...   \n",
       "85063  Disintegrate: [SEP] {X}{R} [SEP] Sorcery [SEP]...   \n",
       "\n",
       "                                text_prompt  \\\n",
       "0                 Fury Sliver: [SEP] {5}{R}   \n",
       "1               Kor Outfitter: [SEP] {W}{W}   \n",
       "2                            Spirit: [SEP]    \n",
       "3               Siren Lookout: [SEP] {2}{U}   \n",
       "4                            Web: [SEP] {G}   \n",
       "...                                     ...   \n",
       "85059                Celestine Reef: [SEP]    \n",
       "85060            Horned Troll: [SEP] {2}{G}   \n",
       "85061     Faerie Bladecrafter: [SEP] {2}{B}   \n",
       "85062  Exultant Skymarcher: [SEP] {1}{W}{W}   \n",
       "85063            Disintegrate: [SEP] {X}{R}   \n",
       "\n",
       "                                        card_description  \n",
       "0      Creature — Sliver [SEP] All Sliver creatures h...  \n",
       "1      Creature — Kor Soldier [SEP] When ~ enters the...  \n",
       "2                   Token Creature — Spirit [SEP] Flying  \n",
       "3      Creature — Siren Pirate [SEP] Flying\\nWhen ~ e...  \n",
       "4      Enchantment — Aura [SEP] Enchant creature (Tar...  \n",
       "...                                                  ...  \n",
       "85059  Plane — Luvion [SEP] Creatures without flying ...  \n",
       "85060          Creature — Troll [SEP] {G}: Regenerate ~.  \n",
       "85061  Creature — Faerie Rogue [SEP] Flying\\nWhenever...  \n",
       "85062            Creature — Vampire Soldier [SEP] Flying  \n",
       "85063  Sorcery [SEP] ~ deals X damage to any target. ...  \n",
       "\n",
       "[82351 rows x 15 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For ZY no csv read\n",
    "#with open('mtgdata.pickle', 'rb') as file:\n",
    "#    mtg_df=pickle.load(file)\n",
    "\n",
    "mtg_df=pd.read_csv('mtg_data.csv', index_col=0)\n",
    "mtg_df=mtg_df.dropna(subset=['text_prompt', 'card_description'])\n",
    "mtg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of prompts is 82351\n",
      "length of descriptions is 82351\n"
     ]
    }
   ],
   "source": [
    "#pre-processing to get rid of unregonizable characters\n",
    "rare_char={\n",
    "    '¡®°²½˝̶π’„•…™−∞☐œŠ':'',\n",
    "    'Äàáâãä':'a',\n",
    "    'Éèéêë':'e',\n",
    "    'Ææ':'ae',\n",
    "    'Óóö':'o',\n",
    "    'úûü':'u',\n",
    "    'íī':'i',\n",
    "    'Ññ':'n'\n",
    "}\n",
    "for rarechar, target in rare_char.items():\n",
    "    for char in [*rarechar]:\n",
    "        mtg_df['text_prompt']=mtg_df['text_prompt'].str.replace(char, target)\n",
    "        mtg_df['card_description']=mtg_df['card_description'].str.replace(char, target)\n",
    "\n",
    "prompt_list=list(mtg_df['text_prompt'])\n",
    "text_list=list(mtg_df['card_description'])\n",
    "print(f'length of prompts is {len(prompt_list)}\\nlength of descriptions is {len(text_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text_list=[torch.Tensor(encode(text)) for text in text_list]\n",
    "max_len=max([len(item) for item in encoded_text_list])\n",
    "padded_text_list=[torch.cat((item, torch.full((max_len - len(item),), 3))) for item in encoded_text_list] # the [PAD] token has id=3\n",
    "padded_text_list_with_CLS = [torch.cat((torch.tensor([1]), item)) for item in padded_text_list]\n",
    "\n",
    "encoded_prompt_list=[torch.Tensor(encode(text)) for text in prompt_list]\n",
    "max_prompt_len=max([len(item) for item in encoded_prompt_list])\n",
    "padded_prompt_list=[torch.cat((item, torch.full((max_prompt_len - len(item),), 3)))[:prompt_size-1] for item in encoded_prompt_list] # the [PAD] token has id=3\n",
    "padded_prompt_list_with_CLS = [torch.cat((torch.tensor([1]), item)) for item in padded_prompt_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pad_sequence(padded_text_list, batch_first=True).long()\n",
    "prompts = pad_sequence(padded_prompt_list_with_CLS, batch_first=True).long()\n",
    "n_train = int(0.9*data.shape[0])\n",
    "train_data = data[:n_train]\n",
    "val_data = data[n_train:]\n",
    "train_prompts = prompts[:n_train]\n",
    "val_prompts = prompts[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   1, 5951,  506,   29,    2,   87,   33,   89,    3,    3,    3,    3,\n",
       "           3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
       "           3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prompts[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split):\n",
    "    #generates a small batch of data input x and target y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.stack([torch.randint(data.shape[0], (batch_size, )), torch.randint(sampling_size, (batch_size, ))]).T\n",
    "    x = torch.stack(tuple(data[i[0]][i[1]:i[1] + block_size] for i in ix))\n",
    "    y = torch.stack(tuple(data[i[0]][i[1] + 1:i[1] + block_size + 1] for i in ix))\n",
    "\n",
    "    prompt_data = train_prompts if split == 'train' else val_prompts\n",
    "    x_prompt = torch.stack(tuple(prompt_data[i[0]] for i in ix))\n",
    "    x_prompt = torch.cat((x_prompt, x), dim=-1)\n",
    "    x_prompt = x_prompt.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    return x_prompt, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out={}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split]=losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "\n",
    "class MaskedHead(nn.Module):\n",
    "    #one self attention head\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias= False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        # compute attention scores\n",
    "        wei = q @ k.transpose(-2, -1) * C**0.5\n",
    "        wei = wei.masked_fill(self.tril[:T, :T]==0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        v=self.value(x)\n",
    "        out=wei @ v\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class MaskedMultiHeadAttention(nn.Module):\n",
    "    \"\"\"multi head attention\"\"\"\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads=nn.ModuleList([MaskedHead(head_size) for _ in range(num_heads)])\n",
    "        self.proj=nn.Linear(head_size*num_heads, n_embd)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.proj(out)\n",
    "        return self.dropout(out)\n",
    "    \n",
    "class Head(nn.Module):\n",
    "    #one self attention head (unmasked)\n",
    "\n",
    "    def __init__(self, encoder_head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(encoder_n_embd, encoder_head_size, bias=False)\n",
    "        self.query = nn.Linear(encoder_n_embd, encoder_head_size, bias= False)\n",
    "        self.value = nn.Linear(encoder_n_embd, encoder_head_size, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        # compute attention scores\n",
    "        wei = q @ k.transpose(-2, -1) * C**0.5\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "\n",
    "        v=self.value(x)\n",
    "        out=wei @ v\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"multi head attention (unmasked)\"\"\"\n",
    "    def __init__(self, encoder_num_heads, encoder_head_size):\n",
    "        super().__init__()\n",
    "        self.heads=nn.ModuleList([Head(encoder_head_size) for _ in range(encoder_num_heads)])\n",
    "        self.proj=nn.Linear(encoder_head_size*encoder_num_heads, encoder_n_embd)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.proj(out)\n",
    "        return self.dropout(out)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    \"\"\"simple feedforward perceptron layer\"\"\"\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net=nn.Sequential(\n",
    "            nn.Linear(n_embd, 4*n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"Transformer encoder block: multihead self attention, followed by feedforward in to k and v\"\"\"\n",
    "    def __init__(self, encoder_n_embd, encoder_n_head):\n",
    "        super().__init__()\n",
    "        encoder_head_size=encoder_n_embd//encoder_n_head\n",
    "        self.selfattention=MultiHeadAttention(encoder_n_head, encoder_head_size)\n",
    "        self.ffwd=FeedForward(encoder_n_embd)\n",
    "        self.ln1=nn.LayerNorm(encoder_n_embd)\n",
    "        self.ln2=nn.LayerNorm(encoder_n_embd)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x+self.sa(self.ln1(x))\n",
    "        x = x+self.ffwd(self.ln2(x))\n",
    "\n",
    "class CrossAttentionHead(nn.Module):\n",
    "    \"\"\"Cross attention block: takes encoder embeddings and decoder embeddings to generate cross attention\"\"\"\n",
    "    def __init__(self, ca_head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(encoder_n_embd, ca_head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, ca_head_size, bias= False)\n",
    "        self.value = nn.Linear(encoder_n_embd, ca_head_size, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, embedded_x_prompt):\n",
    "        x=embedded_x_prompt[:, block_size:, :]\n",
    "        prompt=embedded_x_prompt[:, :block_size, :]\n",
    "        B, T, C = x.shape\n",
    "        B_, T_, C_ = prompt.shape\n",
    "        k = self.key(prompt)\n",
    "        q = self.query(x)\n",
    "        # compute attention scores\n",
    "        wei = q @ k.transpose(-2, -1) * C**0.5\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "\n",
    "        v=self.value(prompt)\n",
    "        out=wei @ v\n",
    "\n",
    "        return out\n",
    "\n",
    "class MultiHeadCrossAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads=nn.ModuleList([CrossAttentionHead(head_size) for _ in range(num_heads)])\n",
    "        self.proj=nn.Linear(head_size*num_heads, n_embd)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, embedded_x_prompt):\n",
    "        out = torch.cat([head(embedded_x_prompt) for head in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return torch.cat((embedded_x_prompt[:, :block_size, :], out), dim=-2)\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"Transformer decoder block: multihead self attention followed by one Feedforward layer, followed by cross-attention, followed by ffwd\"\"\"\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        super().__init__()\n",
    "        head_size = n_embd//n_head\n",
    "        self.sa=MaskedMultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd=FeedForward(n_embd)\n",
    "        self.ln1=nn.LayerNorm(n_embd)\n",
    "        self.ln2=nn.LayerNorm(n_embd)\n",
    "        self.ln3=nn.LayerNorm(n_embd)\n",
    "\n",
    "        self.crossattention=MultiHeadCrossAttention(n_head, head_size) # cross attention module\n",
    "    \n",
    "    def forward(self, embedded_x_prompt):\n",
    "\n",
    "        x=embedded_x_prompt[:, block_size:, :]\n",
    "        x_sa = x+self.sa(self.ln1(x))\n",
    "        x_ca = x_sa+self.crossattention(self.ln2(torch.cat((embedded_x_prompt[:, :block_size, :], x_sa), dim=-2)))[:, block_size:, :] # do cross attention with output of self attention\n",
    "        out_x = x_ca+self.ffwd(self.ln3(x_ca))\n",
    "        out_x_prompt=embedded_x_prompt[:, :block_size, :]\n",
    "\n",
    "        \"\"\"Cross Attention + Feed forward\"\"\"\n",
    "\n",
    "        return torch.cat((out_x_prompt, out_x), dim=-2)\n",
    "\n",
    "\n",
    "class MTGCardGenerator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table=nn.Embedding(vocab_size, n_embd) #each token directly look up the logit of the next token from a lookup table\n",
    "        self.lmhead=nn.Linear(n_embd, vocab_size)\n",
    "        self.position_embedding_table=nn.Embedding(block_size, n_embd) #each token gets a position embeding of block_size, stores the relative position of token in the block\n",
    "\n",
    "        self.encoder_token_embedding_table=nn.Embedding(vocab_size, encoder_n_embd)\n",
    "        self.encoder_postion_embedding_table=nn.Embedding(vocab_size, encoder_n_embd)\n",
    "\n",
    "        self.block=nn.Sequential(*[DecoderBlock(n_embd, n_head=n_heads) for _ in range(n_layers)])\n",
    "    \n",
    "    def forward(self, x_prompt, targets=None, mode=\"train\"):\n",
    "\n",
    "        prompt=x_prompt[:,:block_size]\n",
    "        idx=x_prompt[:,block_size:]\n",
    "        \n",
    "        B, T = idx.shape\n",
    "        B_, T_ = prompt.shape\n",
    "\n",
    "        #idx and targets are both (B,T) tensors of integers, where B=batch number, T=position in batch\n",
    "        token_embeddings=self.token_embedding_table(idx) #look up value corresponding to own position in the token embedding table to form C (channel value)\n",
    "        position_embeddings=self.position_embedding_table(torch.arange(T, device=device)) #add position embeddings to token embedding\n",
    "        x= token_embeddings + position_embeddings\n",
    "        encoder_token_embeddings=self.encoder_postion_embedding_table(prompt)\n",
    "        encoder_position_embeddings=self.encoder_postion_embedding_table(torch.arange(T_, device=device))\n",
    "        prompt_x = encoder_token_embeddings+encoder_position_embeddings\n",
    "\n",
    "        embedded_x_prompt=torch.cat((prompt_x, x), dim=-2)\n",
    "        #returned_x = self.block(embedded_x_prompt)[1]\n",
    "        logits=self.lmhead(self.block(embedded_x_prompt)[:,block_size:,:])\n",
    "\n",
    "        if targets is None:\n",
    "            loss=None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            #logits are therefore values associated with each character\n",
    "            loss=F.cross_entropy(logits, targets) #evaluate loss\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, context, max_new_tokens):\n",
    "        prompt=context[:,:block_size]\n",
    "        idx=context[:,block_size:]\n",
    "        for i in range(max_new_tokens):\n",
    "            if idx.shape[-1]>block_size:\n",
    "            #crop idx to max block size\n",
    "                idx_cond=idx[:, -block_size:]\n",
    "            else:\n",
    "                idx_cond=idx\n",
    "            #get the predictions\n",
    "            logits, loss = self(torch.cat((prompt, idx_cond), dim=-1))\n",
    "            #use logits only, focus only on last time step\n",
    "            logits = logits[:, -1, :] #keep only last time step ---> (B, C)\n",
    "            #apply softmax on logit to get distribution\n",
    "            probs = F.softmax(logits, dim=-1) #get a (B, C) matrix of probabilities, sum(prob) of each B = 1\n",
    "            #sample from the distribution\n",
    "            idx_next=torch.multinomial(probs, num_samples=1) #get a (B, 1) array of predictions\n",
    "            #append prediction to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) #now a (B, T+1) matrix of returned results\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MTGCardGenerator()\n",
    "m=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss: 11.1379, val loss: 11.1383\n",
      "step 300: train loss: 2.5358, val loss: 2.5334\n",
      "step 600: train loss: 2.0772, val loss: 2.1733\n",
      "step 900: train loss: 1.9045, val loss: 1.8495\n"
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "optimizer=torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "for iter in range(max_iters):\n",
    "    # every once in a while evaluate the loss of train and val\n",
    "    if iter % eval_interval == 0:\n",
    "        losses=estimate_loss()\n",
    "        print(f\"step {iter}: train loss: {losses['train']:.4f}, val loss: {losses['val']:.4f}\")\n",
    "    \n",
    "    #sample a batch of data\n",
    "    xb_prompt, yb= get_batch('train')\n",
    "\n",
    "    #evaluate the loss\n",
    "    logits, loss = model(xb_prompt, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 29500])\n",
      "torch.Size([1, 2, 29500])\n",
      "torch.Size([1, 3, 29500])\n",
      "torch.Size([1, 4, 29500])\n",
      "torch.Size([1, 5, 29500])\n",
      "torch.Size([1, 6, 29500])\n",
      "torch.Size([1, 7, 29500])\n",
      "torch.Size([1, 8, 29500])\n",
      "torch.Size([1, 9, 29500])\n",
      "torch.Size([1, 10, 29500])\n",
      "torch.Size([1, 11, 29500])\n",
      "torch.Size([1, 12, 29500])\n",
      "torch.Size([1, 13, 29500])\n",
      "torch.Size([1, 14, 29500])\n",
      "torch.Size([1, 15, 29500])\n",
      "torch.Size([1, 16, 29500])\n",
      "torch.Size([1, 17, 29500])\n",
      "torch.Size([1, 18, 29500])\n",
      "torch.Size([1, 19, 29500])\n",
      "torch.Size([1, 20, 29500])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"}: is turn This Helpful an card the ' t . Caltrops the Armo you t from hand into be\""
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate(cardname, mana):\n",
    "    prompt= torch.tensor([encode(f'[CLS] {cardname}: [SEP] {mana}')], dtype=torch.long, device=device)\n",
    "    padding_values = torch.full((1, prompt_size-prompt.shape[-1]), 3, dtype=torch.long, device=device)\n",
    "    padded_prompt = torch.cat((prompt, padding_values), dim=-1)\n",
    "    start = torch.tensor([encode('[CLS]')], dtype=torch.long, device=device)\n",
    "    context=torch.cat((padded_prompt, start), dim=-1)\n",
    "    response=m.generate(context, max_new_tokens=20)[0].tolist()\n",
    "    return decode(response)\n",
    "generate('The Big Bang', '{2}{R}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
